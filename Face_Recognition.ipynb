{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"face_Recognition.ipynb","provenance":[],"authorship_tag":"ABX9TyM4fTmq9CiX1f1kntX7FTv/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5Ocvs98x4k2l"},"source":["# CNN Model Using Transfer Learning Using VGG 16"]},{"cell_type":"code","metadata":{"id":"F0M97q2v4csw","executionInfo":{"status":"ok","timestamp":1631853374289,"user_tz":-330,"elapsed":2440,"user":{"displayName":"sanil sarathe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimPcJiGZ4otlNx-r5SMvQpDkkej1JwToC8kHXA_w=s64","userId":"09897860592938345614"}}},"source":["from keras.layers import Input, Lambda, Dense, Flatten\n","from keras.models import Model\n","from keras.applications.vgg16 import VGG16\n","from keras.applications.vgg16 import preprocess_input\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","import numpy as np\n","from glob import glob\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"z91XME2A5iNM","executionInfo":{"status":"ok","timestamp":1631853375895,"user_tz":-330,"elapsed":10,"user":{"displayName":"sanil sarathe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimPcJiGZ4otlNx-r5SMvQpDkkej1JwToC8kHXA_w=s64","userId":"09897860592938345614"}}},"source":["# re-size all the images to this\n","IMAGE_SIZE = [224, 224]\n","\n","train_path = 'Datasets/Train'\n","valid_path = 'Datasets/Test'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z9zDoVAo5vv0","executionInfo":{"status":"ok","timestamp":1631853378761,"user_tz":-330,"elapsed":1477,"user":{"displayName":"sanil sarathe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimPcJiGZ4otlNx-r5SMvQpDkkej1JwToC8kHXA_w=s64","userId":"09897860592938345614"}},"outputId":"27dc72d9-3274-45c8-985d-3919dbce2406"},"source":["# odd preprocessing Layer to the front of VGG\n","vgg = VGG16(input_shape = IMAGE_SIZE + [3], weights='imagenet', include_top=False)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 0s 0us/step\n","58900480/58889256 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","metadata":{"id":"QQTmFkSk6T5X","executionInfo":{"status":"ok","timestamp":1631853402352,"user_tz":-330,"elapsed":667,"user":{"displayName":"sanil sarathe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimPcJiGZ4otlNx-r5SMvQpDkkej1JwToC8kHXA_w=s64","userId":"09897860592938345614"}}},"source":["# don't train existing weights\n","for layer in vgg.layers:\n","  layer.trainable = False"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"dWtE63yZ69hm","executionInfo":{"status":"ok","timestamp":1631853403906,"user_tz":-330,"elapsed":11,"user":{"displayName":"sanil sarathe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimPcJiGZ4otlNx-r5SMvQpDkkej1JwToC8kHXA_w=s64","userId":"09897860592938345614"}}},"source":["# useful for getting number of classes\n","folders = glob('Datasets/Train/*')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"YNonDtzm7qPp","executionInfo":{"status":"ok","timestamp":1631853406175,"user_tz":-330,"elapsed":3,"user":{"displayName":"sanil sarathe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimPcJiGZ4otlNx-r5SMvQpDkkej1JwToC8kHXA_w=s64","userId":"09897860592938345614"}}},"source":["# our Layers - you can add more if you want\n","x = Flatten()(vgg.output)\n","# x = Dense(1000, activation='relu')(x)\n","prediction = Dense(len(folders), activation='softmax')(x)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"6_DF4g1u7wZN","executionInfo":{"status":"ok","timestamp":1631853410274,"user_tz":-330,"elapsed":7,"user":{"displayName":"sanil sarathe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimPcJiGZ4otlNx-r5SMvQpDkkej1JwToC8kHXA_w=s64","userId":"09897860592938345614"}}},"source":["# create a model object\n","model = Model(inputs=vgg.input, outputs=prediction)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sleyoBfa8ksG","executionInfo":{"status":"ok","timestamp":1631853416148,"user_tz":-330,"elapsed":498,"user":{"displayName":"sanil sarathe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimPcJiGZ4otlNx-r5SMvQpDkkej1JwToC8kHXA_w=s64","userId":"09897860592938345614"}},"outputId":"79f6ab7b-b1f9-40e2-cb7f-e92583a718dd"},"source":["# view the structure of the model\n","model.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 0)                 0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 0\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"B0ei-HjY8qrD","executionInfo":{"status":"ok","timestamp":1631853419389,"user_tz":-330,"elapsed":491,"user":{"displayName":"sanil sarathe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimPcJiGZ4otlNx-r5SMvQpDkkej1JwToC8kHXA_w=s64","userId":"09897860592938345614"}}},"source":["# tell the model what cost and optimization method to use\n","model.compile(\n","    loss = 'categorical_crossentropy',\n","    optimizer = 'adam',\n","    metrics = ['accuracy']\n",")"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"qtdxIBOs9gqc","executionInfo":{"status":"ok","timestamp":1631853498311,"user_tz":-330,"elapsed":374,"user":{"displayName":"sanil sarathe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimPcJiGZ4otlNx-r5SMvQpDkkej1JwToC8kHXA_w=s64","userId":"09897860592938345614"}}},"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","\n","test_datagen = ImageDataGenerator(rescale = 1./255)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"aJ3EO3tuAF5F","colab":{"base_uri":"https://localhost:8080/","height":387},"executionInfo":{"status":"error","timestamp":1631855867025,"user_tz":-330,"elapsed":382,"user":{"displayName":"sanil sarathe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimPcJiGZ4otlNx-r5SMvQpDkkej1JwToC8kHXA_w=s64","userId":"09897860592938345614"}},"outputId":"4e975195-0f43-4556-848e-675f3a66acd7"},"source":["training_set = train_datagen.flow_from_directory('Datasets/Train',\n","                                                 target_size = (224, 224),\n","                                                 batch_size = 32,\n","                                                 class_mode = 'categorical')"],"execution_count":17,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-b68a2232eccc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                                                  \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                  \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                                  class_mode = 'categorical')\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         interpolation=interpolation)\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m   def flow_from_dataframe(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_path'"]}]},{"cell_type":"code","metadata":{"id":"srlONSM9AezO"},"source":["test_set = test_datagen.flow_from_directory('Datasets/Test',\n","                                            target_size = (224, 224),\n","                                            batch_size = 32,\n","                                            class_mode = 'categorical')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ELCaF0ATA7c4"},"source":["# fit the model\n","r = model.fit_generator(\n","    training_set,\n","    validation_data = test_set,\n","    epochs = 5,\n","    steps_per_epoch = len(training_set),\n","    validation_steps = len(test_set)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rzSxArLiBNQA"},"source":["# loss\n","plt.plot(r.history['acc'], label = 'train acc')\n","plt.plot(r.history['val_acc'], label = 'val acc')\n","plt.legend()\n","plt.show()\n","plt.savefig('AccVal_acc')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GMQJMxL1Bq5v"},"source":["import tensorflow as tf\n","\n","from keras.models import load_model\n","\n","model.save('facefeatures_new_model.h5')"],"execution_count":null,"outputs":[]}]}